{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Baseline\n",
    "Yang Wei Neo, Emily Rapport, Hilary Yamtich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "\n",
    "# Load the pickle file that contains the clean data and other useful stuff?\n",
    "infile = open('./clean_data_pickle','rb')\n",
    "data = pk.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "import csv\n",
    "from rfpimp import *\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# note: this notebook requires pandas 0.21.0 or newer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shared_functions as sf\n",
    "import math\n",
    "from datetime import datetime as dt\n",
    "import re as re\n",
    "\n",
    "# For producing decision tree diagrams.\n",
    "from IPython.core.display import Image, display\n",
    "from sklearn.externals.six import StringIO\n",
    "\n",
    "from dateutil import parser\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "# Run Baseline & Early Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We started with a simple 15% dev set, but we have found that for this amount of data, the differences in the models and their scores on the dev sets can vary significantly based on which rows end up in the train and dev sets. Repeated random sub-sampling cross validation helps us get more consistent results.\n",
    "\n",
    "Note that we do not split out the dev data using the most recent years, which would be the proper way to create a dev set if our task were explicitly to predict future home prices. The test data appears to have rows from all the years represented in the train set, so we built dev sets that sample from across the train set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still to do : choose one version of pandas to use so that our code all agrees\n",
    "# and I don't have to read in a new dataset here \n",
    "data['LogSalePrice'] = np.log(data['SalePrice'])\n",
    "NUM_CROSS_VALS = 5\n",
    "\n",
    "# get the list of different cross val splits\n",
    "cross_val_list = []\n",
    "for i in range(NUM_CROSS_VALS):\n",
    "    split_idx = int(data.shape[0] * .85)\n",
    "    # line below is what shuffles\n",
    "    data = data.sample(frac=1)\n",
    "    train_df = data[:split_idx]\n",
    "    dev_df = data[split_idx:]\n",
    "    split_dict = {'train_df': train_df,\n",
    "                  'dev_df': dev_df}\n",
    "    cross_val_list.append(split_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our primary error metric, we focus on the root mean squared error of the logarithm of the prices, which is the error metric being used to create the leaderboard for this kaggle competition. See rmsle() in shared_functions.py for our implementation of the root mean squared error, an implementation we found from Mark Nagelberg on Kaggle: https://www.kaggle.com/marknagelberg/rmsle-function.\n",
    "\n",
    "When we consulted our resident real estate expert, Hilary's dad, about this problem, he told us that only one of these factors matters - \"location, location, location.\" In the spirit of that insight, we created a baseline \"model\" which looks at what neighborhood the house is in and takes the mean price of houses from that neighborhood in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSLE: 0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangweineo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# todo: figure out why i'm getting nans now\n",
    "# when i wasn't in original notebook\n",
    "def baseline_pred(row,\n",
    "                  train_df):\n",
    "    for col in train_df:\n",
    "        if 'Neighborhood' in col:\n",
    "            if row[col] == 1:\n",
    "                neighborhood_var = col\n",
    "                break\n",
    "    return np.nanmean(train_df[train_df[neighborhood_var]==1]['LogSalePrice'])\n",
    "\n",
    "def get_baseline_cross_val(cross_val_list):\n",
    "    all_rmses = []\n",
    "    for di in cross_val_list:\n",
    "        dev_df = di['dev_df']\n",
    "        dev_df['baseline_pred'] = dev_df.apply(lambda row: baseline_pred(row,\n",
    "                                                                         di['train_df']), axis=1)\n",
    "        rmse = sf.rmsle(list(np.exp(dev_df['LogSalePrice'])), list(np.exp(dev_df['baseline_pred'])))\n",
    "        all_rmses.append(rmse)\n",
    "    return np.nanmean(all_rmses) \n",
    "\n",
    "# baseline RMSLE\n",
    "print(\"Baseline RMSLE: {:.3f}\".format(get_baseline_cross_val(cross_val_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this as a baseline, we began exploring how different types of models perform on the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression\n",
    "\n",
    "We begin with linear regression as the standard choice for a regression problem. In ordinary least squares regression, the regression line is fit by minimizing the sum of squared residuals between the predicted line and the true data points. We can interpret the resulting coefficients on each feature as representing the additional impact of a one-unit change in that feature on the final price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>Num Features</th>\n",
       "      <th>Outcome Var</th>\n",
       "      <th>Params</th>\n",
       "      <th>Root MSE</th>\n",
       "      <th>Train MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Id, MSSubClass, LotArea, OverallQual, Overall...</td>\n",
       "      <td>[ElasticNet(alpha=0.001, copy_X=True, fit_inte...</td>\n",
       "      <td>232</td>\n",
       "      <td>LogSalePrice</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>0.140358</td>\n",
       "      <td>0.111193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Id, MSSubClass, LotArea, OverallQual, Overall...</td>\n",
       "      <td>[Ridge(alpha=2, copy_X=True, fit_intercept=Tru...</td>\n",
       "      <td>232</td>\n",
       "      <td>LogSalePrice</td>\n",
       "      <td>{'alpha': 2}</td>\n",
       "      <td>0.140807</td>\n",
       "      <td>0.105536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Id, MSSubClass, LotArea, OverallQual, Overall...</td>\n",
       "      <td>[LinearRegression(copy_X=True, fit_intercept=T...</td>\n",
       "      <td>232</td>\n",
       "      <td>LogSalePrice</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.147538</td>\n",
       "      <td>0.098785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Id, MSSubClass, LotArea, OverallQual, Overall...</td>\n",
       "      <td>[Lasso(alpha=0.5, copy_X=True, fit_intercept=T...</td>\n",
       "      <td>232</td>\n",
       "      <td>LogSalePrice</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>0.198478</td>\n",
       "      <td>0.181718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Features  \\\n",
       "3  [Id, MSSubClass, LotArea, OverallQual, Overall...   \n",
       "2  [Id, MSSubClass, LotArea, OverallQual, Overall...   \n",
       "0  [Id, MSSubClass, LotArea, OverallQual, Overall...   \n",
       "1  [Id, MSSubClass, LotArea, OverallQual, Overall...   \n",
       "\n",
       "                                               Model  Num Features  \\\n",
       "3  [ElasticNet(alpha=0.001, copy_X=True, fit_inte...           232   \n",
       "2  [Ridge(alpha=2, copy_X=True, fit_intercept=Tru...           232   \n",
       "0  [LinearRegression(copy_X=True, fit_intercept=T...           232   \n",
       "1  [Lasso(alpha=0.5, copy_X=True, fit_intercept=T...           232   \n",
       "\n",
       "    Outcome Var            Params  Root MSE  Train MSE  \n",
       "3  LogSalePrice  {'alpha': 0.001}  0.140358   0.111193  \n",
       "2  LogSalePrice      {'alpha': 2}  0.140807   0.105536  \n",
       "0  LogSalePrice                {}  0.147538   0.098785  \n",
       "1  LogSalePrice    {'alpha': 0.5}  0.198478   0.181718  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_names = ['pca_' + str(i) for i in range(50)]\n",
    "\n",
    "models_to_param_list = {LinearRegression: [{}], \n",
    "                        Lasso: [{'alpha': 0.5}], # lower value is less regularization\n",
    "                        Ridge: [{'alpha': 2}], # more effective with more regularization\n",
    "                        ElasticNet: [{'alpha': 0.001}]} # lower value is less regularization\n",
    "outcome_vars = ['LogSalePrice']\n",
    "feature_sets = [[col for col in data.columns if col not in ['YrMoSold', 'LogSalePrice', 'SalePrice', *pca_names]]]\n",
    "#feature_sets = [pca_names]\n",
    "\n",
    "lrdf = sf.try_different_models(cross_val_list, \n",
    "                               models_to_param_list,\n",
    "                               outcome_vars, \n",
    "                               feature_sets)\n",
    "\n",
    "lrdf.sort_values('Root MSE', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YW SECTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "- Will not work well with variables that are highly correlated with each other\n",
    "- Indeed this is why linear regression with PCA seems to do just as well as the original variables; the  loss is not as great for linear regression (only 0.04 loss in RMSLE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree-based regressors\n",
    "\n",
    "The family of tree-based regressors learns a series of simple decision rules to predict the final sale price. The decision tree regressor makes one single Decision Tree, whereas the Random Forest regressor trains an ensemble of decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Illustration\n",
    "\n",
    "Bagging, or bootstrap aggregation, is intended to reduce variance in the test error by averaging predictions over very specialized models. While each of these models in isolation is likely to overfit, the ensemble of specialized models ends up being very effective at reducing overall test error. To stress test this assumption, we run several random forest ensembles on models that are increasingly less likely to *individually* overfit. We find that the more likely each individual model is to overfit (either by enforcing a smaller minimum leaf, or by enforcing a higher split size), the lower the error of the ensemble as a whole. We suspect that this is because a large ensemble paired with high variance/low bias individual models gives the best of both worlds.\n",
    "\n",
    "Note however that this phenomenon is not true when we increase the proportion of features used to split at each node (causing any given individual tree to be more likely to overfit). We aren't sure why... !!!\n",
    "\n",
    "Another interesting phenomenon is that the difference between the training and test error decreases as each individual model within the ensemble gets less complex. This is a sign of increasing bias in the underlying model, which makes sense, since each model is more likely to underfit since it has less underlying complexity. \n",
    "\n",
    "This analysis suggests that we ought to lean towards creating more complex individual trees (low bias); the higher variance that results from this ought be offset by the bootstrap aggregation procedure. We will use a grid search to find the optimal combination of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list of tests:\n",
    "param_list = []\n",
    "\n",
    "# Create list of parameter types\n",
    "for min_leaf_size in range(10):\n",
    "    param_list.append({'min_samples_leaf': min_leaf_size, 'n_estimators': 50})\n",
    "    \n",
    "for feature_prop in range(10):\n",
    "    param_list.append({'max_features': feature_prop/10, 'n_estimators': 50})\n",
    "                       \n",
    "for split_size in range(11):\n",
    "    param_list.append({'min_samples_split': split_size, 'n_estimators': 50})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run models to show the impact of bagging\n",
    "### THIS TAKES A LONG TIME TO RUN\n",
    "models_to_param_list = {RandomForestRegressor: param_list}\n",
    "feature_sets = [[col for col in data.columns if col not in ['YrMoSold', 'LogSalePrice', 'SalePrice', *pca_names]]]\n",
    "\n",
    "# Run different random forests\n",
    "df = sf.try_different_models(cross_val_list, \n",
    "                             models_to_param_list,\n",
    "                             outcome_vars, \n",
    "                             feature_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,'Bagging with High Variance Models')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a20063048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data\n",
    "fig, ax = plt.subplots(1,3, sharey='row')\n",
    "fig.tight_layout(pad = 1.5)\n",
    "\n",
    "ax[0].plot(df.iloc[0:9]['Root MSE'])\n",
    "ax[0].plot(df.iloc[0:9]['Train MSE'])\n",
    "ax[0].set_xlabel('Min Leaf Size')\n",
    "\n",
    "ax[1].plot(df.iloc[10:20]['Root MSE'])\n",
    "ax[1].plot(df.iloc[10:20]['Train MSE'])\n",
    "ax[1].set_xlabel('% of Features used to split')\n",
    "\n",
    "ax[2].plot(df.iloc[20:30]['Root MSE'])\n",
    "ax[2].plot(df.iloc[20:30]['Train MSE'])\n",
    "ax[2].set_xlabel('Minimum Split Size')\n",
    "\n",
    "fig.suptitle('Bagging with High Variance Models')\n",
    "# !!! remove the axis tick marks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting Illustration\n",
    "\n",
    "In contrast, boosting is a process that reduces bias by refitting the model iteratively on the errors from the previous model. In effect, each model that passes through should be as simple as possible, since subsequent models will weight errors from the prior model more highly. We can see this phenomenon below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize list of tests:\n",
    "param_list = []\n",
    "\n",
    "# Create list of parameter types\n",
    "for depth in range(100):\n",
    "    param_list.append({'max_depth': depth, 'n_estimators': 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models_to_param_list = {GradientBoostingRegressor: param_list}\n",
    "\n",
    "df_boosting = sf.try_different_models(cross_val_list, \n",
    "                             models_to_param_list,\n",
    "                             outcome_vars, \n",
    "                             feature_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_boosting.index, df_boosting['Root MSE'])\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest regressor shows up in the table as the DecisionTreeRegressor with the parentheses around the whole function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Variance Diagnosis\n",
    "\n",
    "#### Random Forests\n",
    "Using random forests, the training data substantially overfits relative to the test data when the complexity of the model is high. This means that most of the error at that point, although lower in absolute terms, is attributable to high variance. \n",
    "\n",
    "#### Gradient Boosting Regression Trees\n",
    "Using Gradient boosting however, we find that the difference in the error between the training and test set is negligible when the model is simpler, suggesting that the underlying problem is a problem of bias. As the tree depth grows, the training set is overfit relative to the test set, and the underlying error stabilizes. \n",
    "\n",
    "#### Conclusion\n",
    "Given that the random forests appear to have a lower absolute error, and given that the underlying problem is variance, not bias when the model is complex, we recommend several fixes to improve the model.\n",
    "\n",
    "#### Recommendations to reduce variance\n",
    "- Ensembling (within the model itself)\n",
    "- Ensembling (with other models)\n",
    "- Reduce the feature set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df.index, df['Root MSE'])\n",
    "plt.scatter(df.index, df['Train MSE'])\n",
    "plt.xlabel('Min Leaf Size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_boosting.index, df_boosting['Root MSE'])\n",
    "plt.scatter(df_boosting.index, df_boosting['Train MSE'])\n",
    "plt.xlabel('Tree Depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where this modeling section is going\n",
    "\n",
    "In our final report, we intend to include more sections of different typess of models and ensembles, and to build out the sections with some deeper explanations.\n",
    "\n",
    "Some things we intend to try:\n",
    "- Bayesian ridge models\n",
    "- K nearest neighbor\n",
    "- Boosting ensembles\n",
    "- Bagging ensembles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis\n",
    "\n",
    "In this section, we'll go into more detail about how we actually iterated on models and chose whichever ones we end up deciding are our best. Our primary tools will be this error correlation table, which we'll use to look at patterns of errors the model is making, and diagnostics to determine whether or not the model is overfitting. We'll compare different models to each other and explain the model or ensemble that gives us the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this still only works on individual models, it doens't average the correlations over a set of models\n",
    "# this tool is really more exploratory than anything - look at a couple models from the set you care about\n",
    "# and see what the trends are\n",
    "\n",
    "# use this variable to specify which model specification to use\n",
    "df_and_row_to_use = lrdf.iloc[0]\n",
    "# use this variable to specify which in the list of models trained with that specification to use\n",
    "model_to_use = df_and_row_to_use['Model'][1]\n",
    "# don't change this\n",
    "features_to_use = df_and_row_to_use['Features']\n",
    "\n",
    "def create_error_correlation_table(model,\n",
    "                                   outcome_var,\n",
    "                                   feature_set,\n",
    "                                   dev_df):\n",
    "    \n",
    "    '''\n",
    "    finds correlation between absolute value of error\n",
    "    and each feature\n",
    "    '''\n",
    "    \n",
    "    final_data = {'col': feature_set}\n",
    "    dev_df = dev_df.reset_index()\n",
    "    \n",
    "    dev_preds = model.predict(dev_df[feature_set])\n",
    "\n",
    "    rmsles = []\n",
    "    for i in range(len(dev_preds)):\n",
    "        rmsles.append(sf.rmsle([dev_df[outcome_var][i]], [dev_preds[i]]))\n",
    "\n",
    "    plt.clf()\n",
    "    plt.hist(rmsles, bins=20)\n",
    "    plt.xlabel(\"RMSLE\")\n",
    "    plt.ylabel(\"Number of Occurrences\")\n",
    "    plt.show()\n",
    "\n",
    "    dev_df['linear_reg_errors'] = rmsles\n",
    "\n",
    "    corrs = []\n",
    "    for col in feature_set:\n",
    "        try:\n",
    "            cor = np.corrcoef(abs(dev_df['linear_reg_errors']), dev_df[col])[0,1]\n",
    "            corrs.append(cor)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    final_data['correlation'] = corrs \n",
    "    \n",
    "    corrs_df = pd.DataFrame(data=final_data)\n",
    "    corrs_df = corrs_df.dropna()\n",
    "    return corrs_df\n",
    "  \n",
    "# table for our LR with all the features\n",
    "corrs_df = create_error_correlation_table(model_to_use, 'LogSalePrice', features_to_use, dev_df)\n",
    "corrs_df.reindex(corrs_df.correlation.abs().sort_values(ascending=False).index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Errors by Key Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cycle through each model variation and plot errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creation of the error plot\n",
    "import shared_functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forest\n",
    "df.sort_values('Root MSE', ascending=True).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear Regression\n",
    "lrdf.sort_values('Root MSE', ascending=True).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Random Forest Errors\n",
    "rf_error_spec = df.sort_values('Root MSE', ascending=True).iloc[0]\n",
    "model_to_use = rf_error_spec['Model'][0]\n",
    "features_to_use = rf_error_spec['Features']\n",
    "plot_features = list(feature_importances[:20].index)\n",
    "plot_error_against_var(model_to_use, 'LogSalePrice', features_to_use, plot_features, dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear Regression Errors\n",
    "# use this variable to specify which model specification to use\n",
    "df_and_row_to_use = lrdf.iloc[0]\n",
    "model_to_use = df_and_row_to_use['Model'][0]\n",
    "features_to_use = df_and_row_to_use['Features']\n",
    "plot_features = list(feature_importances[:20].index)\n",
    "plot_error_against_var(model_to_use, 'LogSalePrice', features_to_use, plot_features, dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMILY - YOUR SECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
