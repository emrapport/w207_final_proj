{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import Binarizer, OneHotEncoder, OrdinalEncoder, add_dummy_feature\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from shared_functions import rmsle, train_and_test, try_different_models\n",
    "import math\n",
    "import graphviz\n",
    "\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "pd.set_option('precision', 4)\n",
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(r\"clean_data.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### todo: add log sale price?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we do a simple split of 10% of our data into a dev set. Eventually, we plan to incorporate cross-validation in order to test our models on different subsets, as we have found that the quality of our models (tested on the dev set) varies drastically across different random splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = int(data_df.shape[0] * .9)\n",
    "data_df = data_df.sample(frac=1)\n",
    "train_df = data_df[:split_idx]\n",
    "dev_df = data_df[split_idx:]\n",
    "del data_df\n",
    "print(train_df.shape)\n",
    "print(dev_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our primary error metric, we focus on the root mean squared error of the logarithm of the prices, which is the error metric being used to create the leaderboard for this kaggle competition. See rmsle() in shared_functions.py for our implementation of the root mean squared error, an implementation we found (where)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a baseline, we created a simple \"model\" which just predicts the median price of the training set. We also tried using the mean, but we found that across different train/dev splits, the median consistently gave us slightly lower root mean squared logarithmic error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_pred(features):\n",
    "    return np.median(train_df['SalePrice'])\n",
    "\n",
    "preds = [baseline_pred(ftrs) for i, ftrs in dev_df.iterrows()]\n",
    "\n",
    "# baseline RMSLE\n",
    "print(\"Baseline RMSLE: {:.3f}\".format(rmsle(list(dev_df['SalePrice']), preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this as a baseline, we began exploring how different types of models perform on the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo: should we add a parsimony metric?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### todo: why do i sometimes get a math domain error? what feature causes that???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin with linear regression as the standard choice for a regression problem. In ordinary least squares regression, the regression line is fit by minimizing the sum of squared residuals between the predicted line and the true data points. We can interpret the resulting coefficients on each feature as representing the additional impact of a one-unit change in that feature on the final price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [LinearRegression(), LinearRegression(normalize=True)]\n",
    "outcome_vars = ['SalePrice']\n",
    "feature_sets = [[col for col in train_df.columns if col not in ['YrMoSold', 'SalePrice']]]\n",
    "lrdf = try_different_models(train_df, dev_df, models, outcome_vars, feature_sets)\n",
    "lrdf.sort_values('Root MSE', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ to explain: normalize makes this way worse - I'm guessing that's because of how many dummy cols we have where the mean overall is going to skew to 0? but then the next time, normalize stayed the same....ugh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree-Based Regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The family of tree-based regressors learns a series of simple decision rules to predict the final sale price. The decision tree regressor makes one single Decision Tree, whereas the Random Forest regressor trains an ensemble of decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [DecisionTreeRegressor(), RandomForestRegressor()]\n",
    "df = try_different_models(train_df, dev_df, models, outcome_vars, feature_sets)\n",
    "df[['Model', 'Num Features', 'Outcome Var', 'Root MSE']].sort_values('Root MSE', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest regressor shows up in the table as the DecisionTreeRegressor with the parentheses around the whole function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's saying the model in the table isn't fit yet, which doesn't really make sense to me\n",
    "# need to figure that out\n",
    "'''dot_data = export_graphviz(df.iloc[1]['Model'], out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"housing\") '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bayesian Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [BayesianRidge()]\n",
    "df = try_different_models(train_df, dev_df, models, outcome_vars, feature_sets)\n",
    "df[['Model', 'Num Features', 'Outcome Var', 'Root MSE']].sort_values('Root MSE', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More sections with particular model types, explanations, visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = lrdf.iloc[0]['Model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_error_correlation_table(model,\n",
    "                                   feature_set,\n",
    "                                   dev_df):\n",
    "    \n",
    "    '''\n",
    "    finds correlation between absolute value of error\n",
    "    and each feature\n",
    "    '''\n",
    "    \n",
    "    dev_preds = model.predict(dev_df[feature_set])\n",
    "    dev_df = dev_df.reset_index()\n",
    "    \n",
    "    rmsles = []\n",
    "    for i in range(len(dev_preds)):\n",
    "        rmsles.append(rmsle([dev_df['SalePrice'][i]], [dev_preds[i]]))\n",
    "        \n",
    "    plt.hist(rmsles, bins=20)\n",
    "    plt.xlabel(\"RMSLE\")\n",
    "    plt.ylabel(\"Number of Occurrences\")\n",
    "    plt.show()\n",
    "    \n",
    "    dev_df['linear_reg_errors'] = rmsles\n",
    "    \n",
    "    cols = []\n",
    "    corrs = []\n",
    "    for col in dev_df.columns:\n",
    "        try:\n",
    "            cor = np.corrcoef(abs(dev_df['linear_reg_errors']), dev_df[col])[0,1]\n",
    "            cols.append(col)\n",
    "            corrs.append(cor)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    corrs_df = pd.DataFrame(data={'col': cols, 'correlation': corrs})\n",
    "    corrs_df = corrs_df.dropna(subset=['correlation'])\n",
    "    return corrs_df\n",
    "    \n",
    "corrs_df = create_error_correlation_table(lr, feature_sets[0], dev_df)\n",
    "corrs_df.reindex(corrs_df.correlation.abs().sort_values(ascending=False).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
